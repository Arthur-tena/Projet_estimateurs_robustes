---
title: "Median of mean"
author: "Arthur TENA"
date: "17/04/2024"
output:  
  html_document:
    toc: yes
    number_sections: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
set.seed(1234)
```


# Introduction :

Étant donné un échantillon de données, l'estimateur MoM mélange les points de données puis les divise en k groupes de m données. Ensuite, il calcule la moyenne arithmétique de chaque groupe. Enfin, nous calculons la médiane des moyennes arithmétiques résultantes.

Cette technique diminue l'effet des valeurs aberrantes sur l'estimation finale en divisant les données et en ne considérant que la médiane des sous-estimations résultantes. 

# Median of mean :

## Codes :

```{r}
median_of_means <- function(X, n) {
  if (n > length(X)) {
    n <- ceiling(length(X) / 2)
  }
  indic <- rep(1:n, each = floor(length(X) / n))
  indic <- sample(indic)
  moyennes <- sapply(1:n, function(block) mean(X[indic == block]))
  return(median(moyennes))
}
```

On améliore un peu l'estimateur en refaisant la même opération plusieurs fois à l'aide de la fonction *replicate* de R l fois et en utilisant la moyenne empirique *mean*.
```{r}
rob_median_of_means <- function(X, n, l) {
  res <- replicate(l, median_of_means(X, n))
  return(mean(res))
}
```


## Exemples :

Nous allons voir dans les exemples plusieurs cas de figure. Un cas de figure ou la moyenne est connue car on utilise les lois usuelles puis un second cas de figure ou les lois ne seront pas définies et donc la moyenne ne sera pas connue.

### Exemples dont la moyenne est connue :

Dans tous nos exmple, nous allons regarder la mediannes des moyennes calculée avec notre fonction, la moyenne à l'aide de la fonction *mean* de R et l'écart quadratique entre les 2 résultats.

[x] N'utilise pas le nombre de blocks optimal  
[ ] Utilise le nombre de block optimal

* Loi gaussienne centrée, de variance $\sigma^2=3$ en 10 blocks 
```{r, echo=TRUE}
M=0
population1=rnorm(1000,M,3)
c(median_of_means(population1, 10),mean(population1),(mean(population1) - median_of_means(population1, 10)) ^ 2)

```

```{r, echo=TRUE}
c(rob_median_of_means(population1, 10, 20),mean(population1),(mean(population1) - rob_median_of_means(population1, 10, 20)) ^ 2)
```
La moyenne est 0 pour une loi normale centrée, on voit que l'erreur quadratique de l'estimateur **median_of_mean** est plus élevée que le deuxième estimateur **rob_median_of_mean** 

* Loi gaussienne de moyenne $\mu=4$ et de variance $\sigma^2=1$ en 10 blocks
```{r, echo=TRUE}
population2=rnorm(1000,4,1)
c(median_of_means(population2, 10),mean(population2),(mean(population2) - median_of_means(population2, 10)) ^ 2)
```

```{r, echo=TRUE}
c(rob_median_of_means(population2, 10, 20),mean(population2),(mean(population2) - rob_median_of_means(population2, 10, 20)) ^ 2)
```
On remarque que l'erreur quadratique est très faible et que les 2 estimateurs **mean** et **median_of_mean** sont relativement proche de la réalité. Ce qui s'explique par le fait que la variance est réduite. On remarque une nouvelle fois que l'estimateur **rob_median_of_mean** est encore significativement plus puissant.

* Loi de Student à k=5 degré de liberté en 10 blocks
```{r}
population3=rt(1000, df=5)
c(median_of_means(population3, 10),mean(population3),(mean(population3) - median_of_means(population3, 10)) ^ 2)
```

```{r}
c(rob_median_of_means(population3, 10, 20),mean(population3),(mean(population3) - rob_median_of_means(population3, 10, 20)) ^ 2)
```
On sait que pour une loi de student de ddl>1, l'espérance est nulle, c'est ce que l'on trouve avec les 2 estimateurs.

[ ]  N'utilise pas le nombre de blocks optimal  
[x] Utilise le nombre de block optimal

```{r}
median_of_means_opt <- function(X, alpha=0.025) {
  n=length(X)
  k <- trunc(8*log(1/alpha))
  m <- n/k
  indic <- rep(1:k, each = m)
  indic <- sample(indic)
  moyennes <- sapply(1:k, function(block) mean(X[indic == block]))
  return(median(moyennes))
}

rob_median_of_means_opt <- function(X, alpha=0.025, l) {
  res <- replicate(l, median_of_means_opt(X, alpha))
  return(mean(res))
}
```

Ici je cherche le coefficient qui minimisera l'erreur

```{r}
library("ggplot2")
median_of_means_opt3 <- function(X, alpha, i) {
  n <- length(X)
  k <- trunc(i * log(1/alpha))
  m <- n / k
  indic <- rep(1:k, each = m)
  sample(indic)
  moyennes <- sapply(1:k, function(block) mean(X[indic == block]))
  return(median(moyennes))
}

population1 <- rexp(10000, 0.2)
rob_median_of_means_opt(population1,0.025, 1000)
population1
alpha <- 0.025
i_values <- 1:30
median_values <- sapply(i_values, function(i) median_of_means_opt3(population1, alpha, i))
data=as.data.frame(cbind(i_values,median_values))
ggplot(data = data, aes(x = i_values, y = median_values)) +
  geom_point() +
  geom_hline(yintercept = 1/2, linetype = "dashed", color = "blue") +
  geom_vline(xintercept = 8, color = "red") +
  geom_vline(xintercept = i_values[which.min(abs(median_values - 0.5))], color = "green") +
  labs(x = "c", y = "Median of Means", title = "Estimateur MoM d'une loi exp(0.2)") +
  geom_text(x = 7, y = 0.491, label = "c_theo", color = "red", vjust = 0.5) +
  geom_text(x = i_values[which.min(abs(median_values - 0.5))]-1, y = 0.491, label = "c_opt", color = "green", vjust = 0.5) +
  theme_classic()
plot(x = i_values, y = median_values, type = "l", xlab = "i", ylab = "Median of Means", main ="Estimateur MoM d'une loi normale centrée réduite")
abline(h=1/2, col='red')
abline(v=8, lty=2, col='blue')
```

```{r}
library("VGAM")
population2 <- rpareto(1000, 1.5, 1.5)
alpha <- 0.025
i_values <- 1:30
median_values <- sapply(i_values, function(i) median_of_means_opt3(population2, alpha, i))
data=as.data.frame(cbind(i_values,median_values))
ggplot(data = data, aes(x = i_values, y = median_values)) +
  geom_point() +
  geom_hline(yintercept = 4.5, linetype = "dashed", color = "blue") +
  geom_vline(xintercept = 8, color = "red") +
  geom_vline(xintercept = i_values[which.min(abs(median_values - 4.5))], color = "green") +
  labs(x = "c", y = "Median of Means", title = "Estimateur MoM d'une loi pareto(1.5,1.5)") +
  geom_text(x = 7, y = 0.491, label = "c_theo", color = "red", vjust = 0.5) +
  geom_text(x = i_values[which.min(abs(median_values - 4.5))]-1, y = 0.491, label = "c_opt", color = "green", vjust = 0.5) +
  theme_classic()
plot(x = i_values, y = median_values, type = "l", xlab = "i", ylab = "Median of Means", main ="Estimateur MoM d'une loi de pareto(1.5,1.5)")
abline(h=4.5, col='red')
abline(v=8, lty=2, col='blue')
print(i_values[which.min(abs(median_values - 4.5))])
```










* Loi gaussienne centrée, de variance $\sigma^2=3$ avec une erreur $\alpha=2.5\%$ 

```{r, echo=TRUE}
alpha=0.025
population1=rnorm(1000,0,3)
#c(median_of_means_opt(population1, alpha),mean(population1),(mean(population1) - median_of_means_opt(population1, alpha)) ^ 2)
IC=c(median_of_means_opt(population1)-2.24*sqrt(var(population1)/length(population1)),median_of_means_opt(population1),median_of_means_opt(population1)+2.24*sqrt(var(population1)/length(population1)))
IC
taille=IC[3]-IC[1]
taille
```

```{r, echo=TRUE}
c(rob_median_of_means_opt(population1, alpha, 20),mean(population1),(mean(population1) - rob_median_of_means_opt(population1, alpha, 20)) ^ 2)
```


```{r}
alpha=0.025
c(median_of_means_opt(population3, alpha),mean(population3),(mean(population3) - median_of_means_opt(population3, alpha)) ^ 2)

c(rob_median_of_means_opt(population3, alpha, 20),mean(population3),(mean(population3) - rob_median_of_means_opt(population3, alpha, 20)) ^ 2)
```



Intervalle de confiance à l'aide d'une méthode de bootstrap
```{r}
bootstrap_IC <- function(data, alpha=0.025, R=1000) {
  bootstrap_estimates <- replicate(R, {
    sample_data <- sample(data, replace = TRUE)
    median_of_means_opt(sample_data, alpha)
  })
  
  lower_bound <- quantile(bootstrap_estimates, 0.025)
  upper_bound <- quantile(bootstrap_estimates, 0.975)
  
  return(c(lower_bound, upper_bound))
}

population1 <- rnorm(1000, 0, 3)


ci <- bootstrap_IC(population4)
ci2 <- bootstrap_IC(population5)
taille <- abs(ci[2]-ci[1])
taille2 <- abs(ci2[2]-ci2[1])

ci2
taille2  

ci
taille
```



On remarque que les 2 estimateurs optiaux donnent les même valeurs.

* Loi log-normale avec $\mu=0$ et $\sigma^2=1$

```{r}
population4=rlnorm(n = 100000, meanlog = 0, sdlog = 1)
c(median_of_means_opt(population4, alpha),mean(population4),(mean(population4) - median_of_means_opt(population4, alpha)) ^ 2)
#IC=c(median_of_means_opt(population4)-2.24*sqrt(var(population4)/length(population4)),median_of_means_opt(population4#),median_of_means_opt(population4)+2.24*sqrt(var(population4)/length(population4)))
#IC
#taille=IC[3]-IC[1]
#taille
```


```{r}
population5=rweibull(n = 1000, shape = 0.5)
c(median_of_means_opt(population5, alpha),mean(population5),(mean(population5) - median_of_means_opt(population5, alpha)) ^ 2)
```



### Exemples dont la moyenne est inconnue :

[x] N'utilise pas le nombre de blocks optimal  
[ ] Utilise le nombre de block optimal

* sample de valeures entières comprises entre -2 et 10 en 10 blocks
```{r}
population_rd1=sample(x = -2:10, size = 1000, replace = TRUE, prob=NULL)
c(median_of_means(population_rd1, 10),mean(population_rd1),(mean(population_rd1) - median_of_means(population_rd1, 10)) ^ 2)
```

```{r}
c(rob_median_of_means(population_rd1, 10, 20),mean(population_rd1),(mean(population_rd1) - rob_median_of_means(population_rd1, 10, 20)) ^ 2)
```

* sample de valeures réelles comprises entre -1 et 1 en 10 blocks
```{r}
population_rd2=sample(x = X(-1,1, by=0.001), size = 1000, replace = TRUE, prob=NULL)
c(median_of_means(population_rd2, alpha),mean(population_rd2),(mean(population_rd2) - median_of_means(population_rd2, alpha)) ^ 2)
```

```{r}
c(rob_median_of_means(population_rd2, alpha, 20),mean(population_rd2),(mean(population_rd2) - rob_median_of_means(population_rd2, alpha, 20)) ^ 2)
```
On remarque que l'estimateur de la médianne des moyennes donne des résultats similaires à la fonction **mean**.

[ ] N'utilise pas le nombre de blocks optimal  
[x] Utilise le nombre de block optimal

* sample de valeures entières comprises entre -2 et 10 avec une erreur $\alpha=2.5\%$
```{r}
c(median_of_means_opt(population_rd1, alpha),mean(population_rd1),(mean(population_rd1) - median_of_means_opt(population_rd1, alpha)) ^ 2)
```

```{r}
c(rob_median_of_means_opt(population_rd1, 10, 20),mean(population_rd1),(mean(population_rd1) - rob_median_of_means_opt(population_rd1, 10, 20)) ^ 2)
```

* sample de valeures réelles comprises entre -1 et 1 avec une erreur $\alpha=2.5\%$
```{r}
c(median_of_means_opt(population_rd2, 10),mean(population_rd2),(mean(population_rd2) - median_of_means_opt(population_rd2, 10)) ^ 2)
```

```{r}
c(rob_median_of_means_opt(population_rd2, 10, 20),mean(population_rd2),(mean(population_rd2) - rob_median_of_means_opt(population_rd2, 10, 20)) ^ 2)
```

* sample de valeures réelles comprises entre -1 et 1 avec une erreur $\alpha=2.5\%$ et une valeure abberante 
```{r}
population_rd3 <- sample(c(runif(1000, -1, 1), 50), 1000, replace = TRUE)
c(median_of_means_opt(population_rd2, 10),mean(population_rd2),(mean(population_rd2) - median_of_means_opt(population_rd2, 10)) ^ 2)
```

```{r}
c(rob_median_of_means_opt(population_rd2, 10, 20),mean(population_rd2),(mean(population_rd2) - rob_median_of_means_opt(population_rd2, 10, 20)) ^ 2)
```


# Conclusion :

On déduit de tout ça qu'avec l'estimateur de la médianne des moyennes on peut estimer de façon significative la moyenne


```{r}
x <- X(from = 0.01, to = 1, by = 0.001)
y <- trunc(8 * log(1 / x))

plot(x = x, y = y, type = "l", col = "blue", ylim = c(0, 40), 
     main = "nombre de blocks en fonction de la valeur de alpha", xlab = "valeur de alpha", ylab = "nb de blocks")

```



```{r}
X1=rpareto(n = 1000, scale = 2.2, 3)

median_of_means_opt2 <- function(X, alpha=0.025) {
  n=length(X)
  k <- (trunc(8*log(1/alpha)))
  m <- n/k
  indic <- rep(1:k, each = m)
  indic <- sample(indic)
  moyennes <- sapply(1:k, function(block) mean(X[indic == block]))
  return(median(moyennes))
}

plot_intervalle <- function(X) {
  alpha <- 0.025
  n <- length(X)
  k <- trunc(8 * log(1 / alpha))
  m <- n / k
  sigma <- 10
  
  Y <- matrix(NA, nrow = 10000, ncol = 5)
  
  for (i in 1:10000) {
    hat_mu <- median_of_means_opt2(X)
    
    y_min <- hat_mu - sigma * sqrt((32*log(1/alpha))/n)
    y_max <- hat_mu + sigma * sqrt((32*log(1/alpha))/n)
    
    taille=y_max-y_min
    
    Y[i, ] <- c(hat_mu,y_min, y_max, taille, abs(hat_mu-10))
  }
  
  plot(Y[, 2], type = "l", ylim = range(Y), col = "blue", main = "Intervalles de confiance", xlab = "Index", ylab = "Valeurs")
  points(Y[, 3], type = "l", col="blue")
  abline(h = hat_mu, col = "red")
  Y=as.data.frame(Y)
  names(Y) <- c("MoM", "y_min", "y_max", "taille", "MoM-mean")
  print(Y)
  print(sigma*sqrt((2*log(1/alpha))/n))
  print((sum(Y[, 5] <=sigma*sqrt((2*log(1/alpha))/n))/10000))
}
plot_intervalle(X1)
```

```{r}
median_of_means <- function(X, k) {
  n=length(X)
  if (k > n) {
    k <- ceiling(length(X) / 2)
  }
  indic <- rep(1:k, each = floor(n / k))
  indic <- sample(indic)
  moyennes <- sapply(1:k, function(block) mean(X[indic == block]))
  return(median(moyennes))
}


plot_int=function(X,k){
  alpha <- 0.025
  n <- length(X)
  m <- trunc(n / k)
  sigma <- sqrt(var(X))
  
  Y <- matrix(NA, nrow = 10000, ncol = 5)
  for (i in 1:10000) {
    hat_mu <- median_of_means(X,k)
    
    y_min <- hat_mu - sigma * sqrt(4/m)
    y_max <- hat_mu + sigma * sqrt(4/m)
    
    taille=y_max-y_min
    
    Y[i, ] <- c(hat_mu,y_min, y_max, taille, abs(hat_mu-mean(X)))
  }
  
  plot(Y[, 2], type = "l", ylim = range(Y), col = "blue", main = "Intervalles de confiance", xlab = "Index", ylab = "Valeurs")
  points(Y[, 3], type = "l", col="blue")
  abline(h = hat_mu, col = "red")
  Y=as.data.frame(Y)
  names(Y) <- c("MoM", "y_min", "y_max", "taille", "MoM-mean")
  print(Y)
  print(sigma*sqrt(4/m))
  print(sum(Y[, 5]>sigma*sqrt(4/m)))
  print(exp(-k/8))
}
X1=rexp(n = 1000, rate=1)
plot_int(X1, 25)
```


```{r}
median_of_means_Minsker <- function(X, k) {
  n <- length(X)
  if (k > n) {
    k <- ceiling(length(X) / 2)
  }
  indic <- combn(X, k)
  moyennes <- apply(indic, 2, mean)
  return(median(moyennes))
}

X4 <- rexp(n = 30, rate = 0.1)
result <- median_of_means_Minsker(X4, 7)
print(result)


# Calculer la médiane des moyennes pour différentes valeurs de k
x <- 1:7
y <- sapply(x, function(k) median_of_means_Minsker(X4, k))

# Tracer la médiane des moyennes en fonction de k
plot(x = x, y = y, type = "b", xlab = "k", ylab = "Median of Means", main = "Median of Means suivant le nombre de blocks k")

```


```{r}
X1=rpareto(n = 10000, scale = 2.2, 3)

median_of_means_opt3 <- function(X) {
  n=length(X)
  alpha=0.025
  k=(trunc(8*log(1/alpha)))
  m <- n/k
  indic <- rep(1:k, each = m)
  indic <- sample(indic)
  moyennes <- sapply(1:k, function(block) mean(X[indic == block]))
  return(median(moyennes))
}
median_of_means_opt3(X1)

plot_intervalle2 <- function(X, sigma, mu, alpha = 0.025) {
  n <- length(X)
  c_values <- seq(sqrt(2), 4 * sqrt(2), by = 0.5)
  
  result <- numeric(length(c_values))
  
  for (i in 1:length(c_values)) {
    c <- c_values[i]
    k <- trunc(8 * log(1 / alpha))
    m <- n / k

    Y <- numeric(1000)
    
    for (j in 1:1000) {
      hat_mu <- median_of_means_opt3(X)
      interval_width <- sigma * c * sqrt(log(1 / alpha) / n)
      Y[j] <- abs(hat_mu - mu) <= interval_width
    }
    
    result[i] <- sum(Y) / length(Y)
  }
  
  # Trouver les valeurs de c pour lesquelles la proportion est proche de 97.5%
  c_optimal_index <- which.min(result >= 1 - alpha)
  c_optimal <- c_values[c_optimal_index]
  
  # Calculer la proportion
  proportion_within_interval <- result[c_optimal_index]
  
  print(paste("Valeur de c pour une proportion de 97.5% :", c_optimal))
  print(proportion_within_interval)
}

plot_intervalle2(X1, 5.5, 8.2915, 0.025)
```


```{r}
Z <- rpareto(1000, shape = 2.2, scale = 3)
estimateur <- replicate(1000, median_of_means_opt3(rpareto(100, shape = 2.2, scale = 3)))

alpha <- 0.025
mu_MoM <- median_of_means_opt3(rpareto(100, shape = 2.2, scale = 3))
n <- length(estimateur)
sigma <- 8.22
sup <- mu_MoM + sigma * sqrt(4.6 * log(1 / alpha) / n) 
inf <- mu_MoM - sigma * sqrt(4.6 * log(1 / alpha) / n)

count_in_intervalle <- sum(estimateur >= inf & estimateur <= sup)
pourcentage <- count_in_intervalle / length(estimateur) * 100


print(paste("Nombre de valeurs dans l'intervalle de confiance :", count_in_intervalle))
print(paste("Pourcentage de valeurs dans l'intervalle de confiance :", pourcentage, "%"))


plot(estimateur, type = "p", col = "blue", xlab = "Valeur de c", ylab = "MoM", main = "Estimateur MoM", ylim=c(inf-1, sup+1))
abline(h = sup, col = "red")
abline(h = inf, col = "red")
```


```{r}
pourcentages <- numeric(400)
ululu <- 0
for (i in 1:400) {
  Z <- rpareto(1000, shape = 2.2, scale = 3)
  estimateur <- replicate(1000, median_of_means_opt3(rpareto(100, shape = 2.2, scale = 3)))

  alpha <- 0.025
  mu_MoM <- median_of_means_opt3(rpareto(100, shape = 2.2, scale = 3))
  n <- length(estimateur)
  sigma <- 8.22
  sup <- mu_MoM + sigma * sqrt(2.9 * log(1 / alpha) / n) 
  inf <- mu_MoM - sigma * sqrt(2.9 * log(1 / alpha) / n)

  count_in_intervalle <- sum(estimateur >= inf & estimateur <= sup)
  pourcentage <- count_in_intervalle / length(estimateur) * 100

  pourcentages[i] <- pourcentage
  if (96.5 <= pourcentage && pourcentage <= 98.5) {
    ululu <- ululu + 1
  }
}

hist(pourcentages, breaks=25, freq=T)

print(paste("Pourcentages stockés :", pourcentages))
print(paste("Nombre de poucentage égale à 97.5 : ", ululu))
```
